{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming process\n",
    "\n",
    "In [demo_pipeline.ipynb](demo_pipeline.ipynb) we showcase the use of the `EvaluatorBuilder`\n",
    "and `EvaluatorPipeline` to create a pipeline that can be used to evaluate \n",
    "the algorithm on a dataset in a particular setting.\n",
    "\n",
    "In the event that the programmer wants to decouple the evaluation platform from\n",
    "the algorithm, that is the algorithm to be instantiated in a seperate process\n",
    "or the algorithm is some online algorithm that can be called on the fly. Then   \n",
    "the programmer can make use of the `EvaluatorStream` class to create a streaming\n",
    "process that can be used to evaluate the algorithm. This removes the burden of\n",
    "instantiating and error handling of the algorithm by the evaluation platform.\n",
    "\n",
    "Similarly to the use of the pipeline, we recommend the programmer to use `EvaluatorStreamerBuilder`\n",
    "to build the streaming object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m - streamsight.datasets.base - \u001b[34mTestDataset is loading dataset...\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m - streamsight.datasets.base - \u001b[34mTestDataset dataset loaded - Took 0.00222s\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 460.05it/s]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m - streamsight.settings.sliding_window_setting - \u001b[34mFinished split with window size 3 seconds. Number of splits: 3 in total.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from streamsight.datasets import TestDataset\n",
    "from streamsight.settings import SlidingWindowSetting\n",
    "dataset = TestDataset()\n",
    "data = dataset.load()\n",
    "setting_window = SlidingWindowSetting(\n",
    "    4,\n",
    "    3,\n",
    "    1,\n",
    "    k\n",
    ")\n",
    "setting_window.split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsight.evaluators import EvaluatorStreamerBuilder\n",
    "\n",
    "builder = EvaluatorStreamerBuilder()\n",
    "builder.add_setting(setting_window)\n",
    "builder.set_metric_K(k)\n",
    "builder.add_metric(\"PrecisionK\")\n",
    "evaluator = builder.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration of algorithm\n",
    "\n",
    "Below we demonstrate how to register an algorithm with the evaluator. The\n",
    "algorithm should ideally inherit from the BaseAlgorithm class.\n",
    "\n",
    "In the event that the algorithm does not inherit from the BaseAlgorithm class,\n",
    "it can be the case that the algorithm might return predictions that are unexpected\n",
    "and error messages might be raised. We also note that the expected data communication\n",
    "is through InterationMatrix objects. Thus, the provided algorithm should be able to\n",
    "handle these objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m - streamsight.evaluators.evaluator_stream - \u001b[34mRegistering algorithm name None with ID: bdd640fb-0667-4ad1-9c80-317fa3b1799d\u001b[0m\n",
      "bdd640fb-0667-4ad1-9c80-317fa3b1799d\n",
      "\u001b[32mINFO    \u001b[0m - streamsight.evaluators.evaluator_stream - \u001b[34mRegistering algorithm name None with ID: 23b8c1e9-3924-46de-beb1-3b9046685257\u001b[0m\n",
      "23b8c1e9-3924-46de-beb1-3b9046685257\n"
     ]
    }
   ],
   "source": [
    "from streamsight.algorithms import ItemKNNIncremental\n",
    "\n",
    "algo = ItemKNNIncremental(K=10)\n",
    "algo_id = evaluator.register_algorithm(algo)\n",
    "print(algo_id)\n",
    "\n",
    "from streamsight.algorithms import ItemKNNStatic\n",
    "external_model = ItemKNNIncremental(K=10)\n",
    "external_model_id = evaluator.register_algorithm(external_model)\n",
    "print(external_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the evaluator is created, we can start the evaluation process by calling\n",
    "the `start_stream` method. This will signal the start of the evaluation process\n",
    "and stop all registration for algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.start_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ItemKNNIncremental(K=10)_bdd640fb-0667-4ad1-9c80-317fa3b1799d': <AlgorithmStateEnum.NEW: 'NEW'>,\n",
       " 'ItemKNNIncremental(K=10)_23b8c1e9-3924-46de-beb1-3b9046685257': <AlgorithmStateEnum.NEW: 'NEW'>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_all_algorithm_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative example 1\n",
    "\n",
    "Here we demonstrate an example of what happens when the external model or programmer\n",
    "calls the API in an out of order fashion. This is not recommended and will result in\n",
    "a warning message. \n",
    "\n",
    "We expect the cycle to be as follows:\n",
    "1. Register algorithm\n",
    "2. Request for training data\n",
    "3. Request for unlabeled data\n",
    "4. Submit predictions\n",
    "6. Repeat 2-4 until the end of the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m - py.warnings - \u001b[34m/Users/ngtzekean/Github/Streamsight/streamsight/evaluators/evaluator_stream.py:296: AlgorithmStatusWarning: Algorithm:bdd640fb-0667-4ad1-9c80-317fa3b1799d current status is NEW.\n",
      "  warn(AlgorithmStatusWarning(algo_id, status, \"unlabeled\"))\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "evaluator.get_unlabeled_data(algo_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected call would be to get the training data first.\n",
    "\n",
    "Note how the status of the algorithm changes on the end of the evaluator platform.\n",
    "The status of the algorithm is updated after each API call to ensure that the\n",
    "algorithm do not receive some data in the future and to ensure that evaluation\n",
    "is in the correct window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ItemKNNIncremental(K=10)_bdd640fb-0667-4ad1-9c80-317fa3b1799d': <AlgorithmStateEnum.READY: 'READY'>,\n",
       " 'ItemKNNIncremental(K=10)_23b8c1e9-3924-46de-beb1-3b9046685257': <AlgorithmStateEnum.NEW: 'NEW'>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = evaluator.get_data(algo_id)\n",
    "algo.fit(data)\n",
    "\n",
    "evaluator.get_all_algorithm_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative example 2\n",
    "\n",
    "Future calls that do not adhere to the expected loop will cause warning messages\n",
    "to be raised, but no exceptions will be thrown. This will allow the programmer\n",
    "to continue executing the code without any interruptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING \u001b[0m - py.warnings - \u001b[34m/Users/ngtzekean/Github/Streamsight/streamsight/evaluators/evaluator_stream.py:249: AlgorithmStatusWarning: Algorithm:bdd640fb-0667-4ad1-9c80-317fa3b1799d current status is READY.\n",
      "  warn(AlgorithmStatusWarning(algo_id, status, \"data_release\"))\n",
      "\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   interactionid  uid  iid  ts\n",
       "0              0    0    0   0\n",
       "1              1    1    0   1\n",
       "2              2    2    1   2\n",
       "3              3    0    2   3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_data(algo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ItemKNNIncremental(K=10)_bdd640fb-0667-4ad1-9c80-317fa3b1799d': <AlgorithmStateEnum.READY: 'READY'>,\n",
       " 'ItemKNNIncremental(K=10)_23b8c1e9-3924-46de-beb1-3b9046685257': <AlgorithmStateEnum.NEW: 'NEW'>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_data = evaluator.get_unlabeled_data(algo_id)\n",
    "evaluator.get_all_algorithm_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ItemKNNIncremental(K=10)_bdd640fb-0667-4ad1-9c80-317fa3b1799d': <AlgorithmStateEnum.PREDICTED: 'PREDICTED'>,\n",
       " 'ItemKNNIncremental(K=10)_23b8c1e9-3924-46de-beb1-3b9046685257': <AlgorithmStateEnum.NEW: 'NEW'>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = algo.predict(unlabeled_data)\n",
    "evaluator.submit_prediction(algo_id, prediction)\n",
    "\n",
    "evaluator.get_all_algorithm_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream to next window\n",
    "\n",
    "When the algorithm is done predicting for the current window, the evaluator will\n",
    "check if all other algorithms are done predicting for the current window. If\n",
    "they are, the evaluator will stream to the next window.\n",
    "\n",
    "Else, the evaluator will wait for the other algorithms to finish predicting and \n",
    "a warning message will be displayed for the current algorithm to wait for the\n",
    "other algorithms to finish predicting. At the moment there is no multi-threading\n",
    "implemented so the algorithms will have to be executed in step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m - streamsight.evaluators.evaluator_stream - \u001b[34mAlgorithm bdd640fb-0667-4ad1-9c80-317fa3b1799d has already predicted for this data segment, please wait for all other algorithms to predict\u001b[0m\n",
      "Algorithm bdd640fb-0667-4ad1-9c80-317fa3b1799d has already predicted for this data segment, please wait for all other algorithms to predict\n"
     ]
    }
   ],
   "source": [
    "data = evaluator.get_data(algo_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive example\n",
    "\n",
    "The following API calls are the expected API calls for a positive example. Ideally\n",
    "the API calls should be in the same order as the code snippet below.\n",
    "\n",
    "While it may not always be possible to adhere to the following call order, the\n",
    "algorithm or programmer who is using streamsight should keep track of the warning\n",
    "messages to ensure that the algorithm does not infinitely wait for data or\n",
    "loop in a cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = evaluator.get_data(external_model_id)\n",
    "external_model.fit(data)\n",
    "unlabeled_data = evaluator.get_unlabeled_data(external_model_id)\n",
    "\n",
    "prediction = external_model.predict(unlabeled_data)\n",
    "evaluator.submit_prediction(external_model_id, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ItemKNNIncremental(K=10)_bdd640fb-0667-4ad1-9c80-317fa3b1799d': <AlgorithmStateEnum.PREDICTED: 'PREDICTED'>,\n",
       " 'ItemKNNIncremental(K=10)_23b8c1e9-3924-46de-beb1-3b9046685257': <AlgorithmStateEnum.PREDICTED: 'PREDICTED'>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_all_algorithm_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = evaluator.get_data(algo_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>micro_score</th>\n",
       "      <th>num_user</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ItemKNNIncremental(K=10)_23b8c1e9-3924-46de-beb1-3b9046685257</th>\n",
       "      <th>PrecisionK_10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemKNNIncremental(K=10)_bdd640fb-0667-4ad1-9c80-317fa3b1799d</th>\n",
       "      <th>PrecisionK_10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 micro_score  \\\n",
       "Algorithm                                          Metric                      \n",
       "ItemKNNIncremental(K=10)_23b8c1e9-3924-46de-beb... PrecisionK_10         0.1   \n",
       "ItemKNNIncremental(K=10)_bdd640fb-0667-4ad1-9c8... PrecisionK_10         0.1   \n",
       "\n",
       "                                                                  num_user  \n",
       "Algorithm                                          Metric                   \n",
       "ItemKNNIncremental(K=10)_23b8c1e9-3924-46de-beb... PrecisionK_10         1  \n",
       "ItemKNNIncremental(K=10)_bdd640fb-0667-4ad1-9c8... PrecisionK_10         1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.metric_results(\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>macro_score</th>\n",
       "      <th>num_window</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ItemKNNIncremental(K=10)_23b8c1e9-3924-46de-beb1-3b9046685257</th>\n",
       "      <th>PrecisionK_10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemKNNIncremental(K=10)_bdd640fb-0667-4ad1-9c80-317fa3b1799d</th>\n",
       "      <th>PrecisionK_10</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  macro_score  \\\n",
       "Algorithm                                          Metric                       \n",
       "ItemKNNIncremental(K=10)_23b8c1e9-3924-46de-beb... PrecisionK_10          0.1   \n",
       "ItemKNNIncremental(K=10)_bdd640fb-0667-4ad1-9c8... PrecisionK_10          0.1   \n",
       "\n",
       "                                                                  num_window  \n",
       "Algorithm                                          Metric                     \n",
       "ItemKNNIncremental(K=10)_23b8c1e9-3924-46de-beb... PrecisionK_10           1  \n",
       "ItemKNNIncremental(K=10)_bdd640fb-0667-4ad1-9c8... PrecisionK_10           1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.metric_results(\"macro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
