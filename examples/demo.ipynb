{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Splitting\n",
    "\n",
    "The loading mechanism gets the class of dataset that the user wants to use for\n",
    "evaluation on his algorithmn.\n",
    "\n",
    "The splitting will take in a split type and create the necessary split on the\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsight.splits import SingleTimePointSetting\n",
    "from streamsight.datasets import AmazonMusicDataset\n",
    "\n",
    "dataset = AmazonMusicDataset()\n",
    "# yelp or amazon as a base instead\n",
    "# movielens timestamp curtting might be problematic\n",
    "data = dataset.load()\n",
    "\n",
    "# user creates his own custom dataset class if needed\n",
    "setting = SingleTimePointSetting(\n",
    "    1406851200,\n",
    "    1398556800\n",
    ")\n",
    "# once a setting is defined, it can be used to split data\n",
    "# the data will be stored in the attribute of the setting object\n",
    "setting.split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Algorithm\n",
    "\n",
    "Training the RecSys algorithm is as straight forward. The choice of the algorithm\n",
    "is selected by instantiating the class of algorithm choice then training the\n",
    "model with the dataset from the setting. The setting class provides multiple\n",
    "public attribute calls that can be used by the programmer.\n",
    "\n",
    "We will demo a simple example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Single global timeline split #############\n",
    "# The class of the algorithm tho be tested can be instantiated\n",
    "from streamsight.algorithms.itemknn import ItemKNN\n",
    "\n",
    "\n",
    "algo = ItemKNN()\n",
    "# each algorithm has a fit method that takes the training data and fits the model\n",
    "algo.fit(setting.background_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsight.metrics.precision import PrecisionK\n",
    "\n",
    "\n",
    "X_pred = algo.predict(setting.unlabeled_data_series)\n",
    "metric = PrecisionK(10)\n",
    "metric.calculate(setting.ground_truth_data_series.binary_values, X_pred)\n",
    "metric.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for sliding window setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Sliding window split #############\n",
    "from streamsight.algorithms import ItemKNNIncremental\n",
    "algo = ItemKNNIncremental()\n",
    "\n",
    "# itemknn\n",
    "# (1) use the inital batch of data and no change aka no new learning\n",
    "# (2) inital batch and update with new batch add more data essentially\n",
    "# (3) just use the new batch of data\n",
    "\n",
    "background_data = setting.background_data\n",
    "algo.fit(background_data)\n",
    "\n",
    "for _ in range(setting.num_split_set):\n",
    "    unlabeled_data = setting.next_unlabeled_data()\n",
    "    ground_truth_data = setting.next_ground_truth_data()\n",
    "\n",
    "    # Eval model\n",
    "    X_pred = algo.predict(setting.unlabeled_data_series)\n",
    "    metric = PrecisionK(10)\n",
    "    metric.calculate(setting.ground_truth_data_series.binary_values, X_pred)\n",
    "    print(metric.value)\n",
    "\n",
    "    # Release ground truth to model\n",
    "    current_training_set = ground_truth_data\n",
    "    algo.fit(current_training_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline to streamline API usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_builder = PipelineBuilder()\n",
    "pipeline_builder.set_dataset(AmazonMusicDataset)\n",
    "pipeline_builder.set_splitter(SingleTimePointSetting)\n",
    "pipeline_builder.add_algorithm([\"KNN\",\"UserKNN\"])\n",
    "\n",
    "# incremental issue: on the algo \n",
    "algo.get_train_data()\n",
    "algo.get_test_data()\n",
    "\n",
    "\n",
    "pipeline_builder.add_metric(\"Recall\")\n",
    "pipeline_builder.add_metric(\"Precision\")\n",
    "\n",
    "############# Running pipeline as a whole #############\n",
    "# provide ability to step through each window \n",
    "pipeline = pipeline_builder.build()\n",
    "pipeline.run()\n",
    "\n",
    "############# Running pipeline by stepping #############\n",
    "# provide ability to step through each window \n",
    "pipeline = pipeline_builder.build()\n",
    "pipeline.step(n=1,verbose=True)\n",
    "pipeline.display_metrics() # show metrics for the current window\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
