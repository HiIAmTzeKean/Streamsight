{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamsight basic demo\n",
    "\n",
    "Streamsight is a toolkit for recommendation systems. It is designed to provide\n",
    "a comprehensive set of tools for the entire lifecycle of a recommendation\n",
    "system, from the loading of dataset to the evaluation of the algorithms.\n",
    "\n",
    "To install the toolkit, run `pip install streamsight`\n",
    "\n",
    "The framework shown below will be covered in this demo to showcase to the\n",
    "programmer how to utilise this toolkit.\n",
    "\n",
    "![framework](img/sliding_setting_scheme-detailed_framework.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load\n",
    "\n",
    "The first segment of this demo covers the data load process for the demo. We will\n",
    "cover the choice of dataset that the user can choose from first. The selection\n",
    "of the dataset includes various dataset from Amazon and Yelp. The programmer\n",
    "can choose his desired choice and instantiate an instance of the dataset as\n",
    "shown below.\n",
    "\n",
    "Furthermore, preprocessing filters such as `MinItemPerUser` is provided to the\n",
    "programmer to filter the dataset on. There will be a default preprocessing\n",
    "step that will be applied to all dataset - internal user and item id will be\n",
    "created and replaces the original id. Please read the documentation for more\n",
    "information on this in the preprocessing class.\n",
    "\n",
    "To load the dataset, the programmer will invoke the method `load` to load the\n",
    "dataset into memory. Please note that some datasets are huge and will take\n",
    "some time to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsight.datasets import AmazonMusicDataset\n",
    "from streamsight.preprocessing import MinItemsPerUser\n",
    "\n",
    "dataset = AmazonMusicDataset()\n",
    "dataset.add_filter(\n",
    "    MinItemsPerUser(5, AmazonMusicDataset.ITEM_IX, AmazonMusicDataset.USER_IX)\n",
    ")\n",
    "data = dataset.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be the splitting of the data. For the traditional split (single time point)\n",
    "that is a single timestamp is chosen as the time value to split the data into train and test sets,\n",
    "there will only be one split. For the sliding temporal split discussed in the paper which is being\n",
    "implemented, there will be multiple splits, each split will have a different time value to split the\n",
    "data into train and test sets.\n",
    "\n",
    "For the purposes of `streamsight` the traditional terminology of train and test sets is replaced with\n",
    "background and ground truth. As for the prediction to be made, we call the set unlabeled data which\n",
    "the algorithm must predict on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsight.settings import SingleTimePointSetting\n",
    "\n",
    "setting = SingleTimePointSetting(\n",
    "    background_t=1406851200,\n",
    "    delta_after_t=1398556800,\n",
    "    n_seq_data=1\n",
    ")\n",
    "# once a setting is defined, it can be used to split data\n",
    "# the data will be stored in the attribute of the setting object\n",
    "setting.split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsight.settings import SlidingWindowSetting\n",
    "\n",
    "setting_window = SlidingWindowSetting(\n",
    "    background_t=1406851200,\n",
    "    window_size=60 * 60 * 24 * 10, # 10 days\n",
    "    n_seq_data=1,\n",
    ")\n",
    "setting_window.split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RecSys training\n",
    "\n",
    "Training the RecSys algorithm is as straight forward. The choice of the algorithm\n",
    "is selected by instantiating the class of algorithm choice then training the\n",
    "model with the dataset from the setting. The setting class provides multiple\n",
    "public function calls that can be used by the programmer.\n",
    "\n",
    "As the algorithm that is designed in this package is a basic algorithm, some\n",
    "extra processing step must be done on our end to treat the shape of the dataset\n",
    "for the algorithm such that it is able to run successfully.\n",
    "\n",
    "Note that the treating of the dataset is an optional parameter that the\n",
    "programmer can choose not to apply in this platform. This will allow flexibility\n",
    "on the programmer's end to evaluate the algorithm's capability.\n",
    "\n",
    "We will demo a simple example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Single global timeline split #############\n",
    "from streamsight.algorithms import ItemKNNStatic\n",
    "\n",
    "algo = ItemKNNStatic(K=10)\n",
    "\n",
    "# Note that the data feed to the model must first be masked before\n",
    "# it is fed to the model. The rational for this is to define the set\n",
    "# of known user/item base knowledge such that the evaluation is\n",
    "# well defined.\n",
    "setting.background_data.mask_shape()\n",
    "# each algorithm has a fit method that takes the training data and fits the model\n",
    "algo.fit(setting.background_data)\n",
    "\n",
    "setting.unlabeled_data.mask_shape(setting.background_data.shape, True, True)\n",
    "X_pred = algo.predict(setting.unlabeled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The evaluation is done by comparing the predicted values with the true values. Below\n",
    "we show a simple example of how to evaluate the prediction manually. The specific\n",
    "class of metric will be instantiated and then used to calculate the score.\n",
    "\n",
    "The above demo is to showcase how the pipeline and streamer work under the hood.\n",
    "The recommended way to train and evaluate the algorithm on is to either\n",
    "use the class `EvaluatorPipeline` or `EvaluatorStreamer` which are designed to\n",
    "abstract the process and to allow the programmer to specify the parameters\n",
    "needed to train the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsight.metrics import PrecisionK\n",
    "\n",
    "# Here we mask the ground truth data to match the shape of the prediction\n",
    "# data. By dropping unknown users and items, we are only evaluating the\n",
    "# users and items that are only known to the model.\n",
    "setting.ground_truth_data.mask_shape(setting.background_data.shape,\n",
    "                                     drop_unknown_user=True,\n",
    "                                     drop_unknown_item=True)\n",
    "\n",
    "metric = PrecisionK(10)\n",
    "metric.calculate(setting.ground_truth_data.binary_values, X_pred)\n",
    "print(\"The macro result of the algorithm is: {metric.macro_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation for sliding window setting\n",
    "\n",
    "The evaluation for the sliding window setting case is a lot more complex and\n",
    "uses an array of `InterationMatrix` unlike the single time point setting. For the\n",
    "purposes of this demo, we will skip the code for the sliding window as it is the\n",
    "same as the one above.\n",
    "\n",
    "The difference is that the unlabeled_data and grouth_truth_data are now a list.\n",
    "To get the the specific element, a simple list indexing would do. An example is\n",
    "shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_window.unlabeled_data[1]._df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline to streamline API usage\n",
    "\n",
    "The pipeline built uses an `Evaluator` class to help us run the entire process of\n",
    "instantiating the model, data feed and metrics for us. To build the `Evaluator`\n",
    "the builder class must first be created as shown below. Following the creation,\n",
    "the programmer will define the algorithm/model of interest followed by the setting\n",
    "that was created earlier along with the metric of interest.\n",
    "\n",
    "Note that multiple algorithms and metrics can be added to the builder, allowing\n",
    "for evaluation of multiple algorithms and metrics over a single run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamsight.evaluators import EvaluatorBuilder\n",
    "\n",
    "builder = EvaluatorBuilder(\n",
    "                     ignore_unknown_user=True,\n",
    "                     ignore_unknown_item=True\n",
    "                     )\n",
    "builder.add_setting(setting)\n",
    "builder.add_algorithm(\"ItemKNNIncremental\", {\"K\": 10})\n",
    "builder.add_metric(\"PrecisionK\", K=10)\n",
    "builder.add_metric(\"RecallK\", K=10)\n",
    "evaluator = builder.build()\n",
    "\n",
    "evaluator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.metric_results(\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.metric_results(\"macro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
