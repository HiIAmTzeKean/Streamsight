---
date: 03--Feb--2024
stage: 
description: 
tags: 
modified: 03--Feb--2024
---
# 03--Feb--2024
## Objective
>[!question] What are some assumptions that I should have in the system

## Material read
1. 
## Reflection
![[Guiding questions]]

### Observation 1
What are some key assumptions and perspective that I should come up with?
Based on the flow of the system. We can structure the system to be as such
1. Data source is taken
2. Define hyper-parameter (window size)
3. Some partitioning is done window based
4. Models are given train data
5. Models are asked to predict
6. Evaluation is done on prediction
7. We repeat step 3-5 by sliding the window forward

Based on [[sunTakeFreshLook2023]], some assumptions that I can extract would be

Observing the data available, we can see that some dataset does not contain timestamp for data partitioning. Thus, only suitable datasources such like Amazon and Yelp should be used.
→ We assume that our data source contains timestamp for each interaction

We also want to observe that dataset that we use are spread across different days or timestamp. There could be a case where interactions are grouped into single timestamps or a single day such as in MovieLens, partitioning such sources will lead to no meaningful testing since a user will either be known or unknown
→ Interactions are spread across a timeline suitable for splitting

From the repo observed, we can also assume that the models that we are evaluating should contain basic API that the Evaluator can call. Some API could be `train(dataset)`, `pred(user)`
→ We assume a set of API from models that we can call in our Eval Sys
### Observation 2
To categorise these assumptions, we can bucket them into groups
- Data source
- Architecture